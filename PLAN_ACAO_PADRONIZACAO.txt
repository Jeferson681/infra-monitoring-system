Plano de Ação — Padronização JSONL e Agregação Horária
Data: 2025-10-02
Autor: (automatizado)

Objetivo
- Padronizar o conteúdo das entradas JSONL produzidas a cada ciclo.
- Garantir que a agregação horária (hourly average) use janelas de 1 hora corretas
  e seja executada apenas quando houver dados suficientes.
- Preservar a saída humana em formato idêntico ao console -vv no arquivo
  `monitoring-hourly-YYYY-MM-DD.log` (multi-line).

Prioridades
1) Corrigir agendamento e estado do hourly (alto impacto)
2) Preservar formatação humana multi-line no arquivo hourly (médio)
3) Padronizar schema JSONL e reduzir duplicação (alto esforço)
4) Migrar/limpar estado antigo e adicionar testes/instrumentação

Passos detalhados (ordem sugerida)

Passo 1 — Sequenciamento correto da agregação horária (run_hourly_aggregation)
- Arquivo(s): src/monitoring/averages.py, src/main.py
- Objetivo: garantir que apenas se processe uma janela horária completa por vez
  (janela = 3600s). Não basear a decisão em time.time() sozinho; usar timestamps
  presentes nos JSONL e o `last_end_ts` persistido.
- Atividades:
  1. Refatorar run_hourly_aggregation para o seguinte fluxo:
     a) Ler state = last_end_ts (0 se ausente).
     b) Se last_end_ts == 0 (primeira execução): determinar max_ts dos JSONL.
        - Se max_ts >= start_window + window_seconds (ou seja, há 1h de dados),
          processar [max_ts - window, max_ts] e set last_end_ts = int(max_ts).
        - Caso contrário, logar "no full hour yet" e NÃO atualizar last_end_ts.
     c) Se last_end_ts > 0: target_end = last_end_ts + window_seconds.
        - Se max_ts >= target_end, processar [target_end - window, target_end]
          e atualizar last_end_ts = target_end.
        - Caso contrário aguardar (não processar).
  2. Persistir estado em logs/.cache/.hourly_state.json (migrar antigo se presente).
- Testes:
  - Unit: simular JSONL com timestamps e verificar que cada invocação processa
    no máximo uma janela (atualiza last_end_ts corretamente).
  - Integration: criar JSONL com N horas e executar run_hourly_aggregation
    sequencialmente, validar geração de N arquivos hourly.
- Critério de aceitação: ao executar main por ciclos curtos, o hourly é gerado no
  máximo uma vez por hora lógica (por dados), não a cada 25s.

Passo 2 — Preservar formatação humana multi-line para monitoring-hourly
- Arquivo(s): src/monitoring/averages.py, possivelmente system/log_helpers.py
- Objetivo: garantir que a saída humana gravada em `monitoring-hourly-YYYY-MM-DD.log`
  seja legível e mantenha quebras de linha do console -vv. Em vez de criar um
  escritor separado, usar `write_log(..., hourly=True)` como API centralizada que
  respeita políticas de janela e gravação, e ajustar formatters/formatters se
  for necessário para preservar quebras.
- Atividades:
  1. Usar `write_log(..., hourly=True)` para gravação humana por hora.
  2. Se necessário, ajustar `system/log_helpers.build_human_line` para não
     normalizar quebras quando a entrada for um bloco multi-line (opcional).
- Testes:
  - Gerar um sample human multi-line e verificar que o arquivo contém múltiplas linhas
    na mesma entrada (não concatenadas).
- Critério de aceitação: leitura do log mostra o bloco multi-line igual ao console.

Passo 3 — Padronizar schema JSONL
- Arquivo(s): src/monitoring/metrics.py, src/system/log_helpers.py, src/system/logs.py
- Proposta de schema (fields recomendados):
  - timestamp: float (epoch)  -- obrigatório
  - level: str
  - msg: str
  - state: str
  - metrics_raw: {
      cpu_percent, memory_percent, memory_used_bytes, memory_total_bytes,
      disk_percent, disk_used_bytes, disk_total_bytes, ping_ms, latency_ms }
  - summary_short: str
  - summary_long: [str]
  - alerts: [{name, value, level}]
  - schema_version: str (ex: "v1")
- Atividades:
  1. Atualizar o builder JSON (build_json_entry) para aplicar o schema.
  2. Atualizar os pontos que chamam write_log para preencher `extra` com
     metrics_raw (em vez de duplicar top-level keys).
  3. Manter compatibilidade de leitura em _extract_metric_value (aceitar
     top-level e snapshot por enquanto) mas adicionar testes que o novo JSONL
     está correto.
- Testes:
  - Unit: validar o builder gera o JSON com as keys corretas e sem duplicação.
  - Integration: produzir JSONL e validar parsing por _collect_samples.
- Critério de aceitação: entradas JSONL seguem o schema e não duplicam métricas.

Passo 4 — Migração e limpeza
- Migrar logs/.hourly_state.json (antigo) para logs/.cache/.hourly_state.json
  automaticamente na inicialização se o novo não existir.
- Opcional: adicionar comando CLI `scripts/migrate_state.py` para executar migração
  manualmente.

Passo 5 — Testes e deploy local
- Adicionar testes novos:
  - tests/monitoring/test_hourly_sequencing.py
  - tests/system/test_jsonl_schema.py
- Executar: pytest tests/monitoring -q
- Manual smoke: executar main por N ciclos com MONITORING_HOURLY_CHECK_INTERVAL_SEC=60
  e verificar `logs/log/monitoring-hourly-YYYY-MM-DD.log` e `logs/json/monitoring-YYYY-MM-DD.jsonl`.

Comandos úteis
- Rodar testes de averages:
  $env:PYTHONPATH = 'src'; pytest tests/monitoring/test_averages.py -q
- Rodar main local por 10 ciclos (Windows PowerShell):
  $env:PYTHONPATH = 'src'; python src/main.py -i 1 -c 10 -vv
- Rodar com scheduler de checagem do hourly a cada 60s:
  $env:MONITORING_HOURLY_INTERVAL_SEC = '60'; $env:PYTHONPATH = 'src'; python src/main.py -i 1 -c 120 -vv

Rollback / segurança
- Antes de trocar schema JSONL, adicionar `schema_version` nas novas linhas.
- Manter _extract_metric_value compatível com formatos antigos até que
  todos consumidores sejam atualizados.

Cronograma estimado (para eu implementar A e B se desejar)
- Implementar sequenciamento e state migration (Passo 1 + 4): 1 a 2h
- Implementar gravação human multiline (Passo 2): 30m
- Testes unitários e integração (Passo 1-2): 1h
- Padronizar schema (Passo 3): 2-4h (mais testes)

Responsabilidades / checkpoints
- Após cada PR ou patch: executar os testes unitários e uma execução curta do main;
  revisar os arquivos em logs/json e logs/log para confirmar comportamento.

Notas finais
- Prefira deploy incremental: primeiro a coordenação do hourly (evita médias erradas),
  depois padronização do JSONL (maior impacto).
- Se quiser, eu executo as alterações prioritárias (Passo 1 + 2) e mostro os resultados.

--- Fim do Plano ---
